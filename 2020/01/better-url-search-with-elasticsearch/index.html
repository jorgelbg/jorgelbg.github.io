<!doctype html><html lang=en-us><head><link rel=preload href=//jorgelbg.me/css/style.css as=style><link rel=stylesheet href=//jorgelbg.me/css/style.css media=print onload="this.media='all'"><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge,chrome=1"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=author content="Jorge Luis Betancourt"><meta name=description content="Computo Ergo Sum"><meta name=generator content="Hugo 0.80.0"><title>Better URL search with Elasticsearch</title><link rel="shortcut icon" href=//jorgelbg.me/favicon.ico><link rel=apple-touch-icon sizes=180x180 href=/apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/favicon-16x16.png><link rel=manifest href=//jorgelbg.me/site.webmanifest><link rel=mask-icon href=//jorgelbg.me/safari-pinned-tab.svg color=#5bbad5><meta name=msapplication-TileColor content="#da532c"><meta name=theme-color content="#ffffff"><link rel=dns-prefetch href=//www.google-analytics.com/><link href=//jorgelbg.me/index.xml rel=alternate type=application/rss+xml title="Jorge Luis Betancourt"><meta property="og:title" content="Better URL search with Elasticsearch"><meta property="og:description" content="Improved URL search in Elasticsearch using custom analyzers."><meta property="og:type" content="article"><meta property="og:url" content="//jorgelbg.me/2020/01/better-url-search-with-elasticsearch/"><meta property="article:published_time" content="2020-01-01T11:46:14-05:00"><meta property="article:modified_time" content="2020-05-21T16:32:15+02:00"><meta itemprop=name content="Better URL search with Elasticsearch"><meta itemprop=description content="Improved URL search in Elasticsearch using custom analyzers."><meta itemprop=datePublished content="2020-01-01T11:46:14-05:00"><meta itemprop=dateModified content="2020-05-21T16:32:15+02:00"><meta itemprop=wordCount content="1027"><meta itemprop=keywords content="elasticsearch,search,url,"><meta name=twitter:card content="summary"><meta name=twitter:title content="Better URL search with Elasticsearch"><meta name=twitter:description content="Improved URL search in Elasticsearch using custom analyzers."><meta name=twitter:site content="@jorgelbg"></head><body><section id=wrapper><nav class=main-nav><a href=//jorgelbg.me></a></nav><article class=post><header><h1><a href=//jorgelbg.me/2020/01/better-url-search-with-elasticsearch/><svg aria-hidden="true" height="24" viewBox="0 0 16 16" width="20"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5.0-3-1.69-3-3.5S2.55 3 4 3h4c1.45.0 3 1.69 3 3.5.0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98.0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98.0-2-1.22-2-2.5.0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45.0 3-1.69 3-3.5S14.5 6 13 6z"/></svg>Better URL search with Elasticsearch</a></h1><h2 class=headline><span>January 1, 2020</span>
<span class=tag><svg fill="#718096" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" width="16" height="16"><path class="heroicon-ui" d="M2.59 13.41A1.98 1.98.0 012 12V7a5 5 0 015-5h4.99c.53.0 1.04.2 1.42.59l8 8a2 2 0 010 2.82l-8 8a2 2 0 01-2.82.0l-8-8zM20 12l-8-8H7A3 3 0 004 7v5l8 8 8-8zM7 8a1 1 0 110-2 1 1 0 010 2z"/></svg><a style=margin-left:10px href=//jorgelbg.me/tags/elasticsearch>elasticsearch</a></span>
<span class=tag><svg fill="#718096" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" width="16" height="16"><path class="heroicon-ui" d="M2.59 13.41A1.98 1.98.0 012 12V7a5 5 0 015-5h4.99c.53.0 1.04.2 1.42.59l8 8a2 2 0 010 2.82l-8 8a2 2 0 01-2.82.0l-8-8zM20 12l-8-8H7A3 3 0 004 7v5l8 8 8-8zM7 8a1 1 0 110-2 1 1 0 010 2z"/></svg><a style=margin-left:10px href=//jorgelbg.me/tags/search>search</a></span>
<span class=tag><svg fill="#718096" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" width="16" height="16"><path class="heroicon-ui" d="M2.59 13.41A1.98 1.98.0 012 12V7a5 5 0 015-5h4.99c.53.0 1.04.2 1.42.59l8 8a2 2 0 010 2.82l-8 8a2 2 0 01-2.82.0l-8-8zM20 12l-8-8H7A3 3 0 004 7v5l8 8 8-8zM7 8a1 1 0 110-2 1 1 0 010 2z"/></svg><a style=margin-left:10px href=//jorgelbg.me/tags/url>url</a></span></h2><p class=last-edited><a href=https://github.com/jorgelbg/jorgelbg.github.io/commit/9570c46ec483f655755dbac48b3817d9510067f0 title='Simplify cross post announcement for "Better URL search with Elasticsearch" post'>Last edited on 21 May 2020</a></p></header><section id=post-body><blockquote><p>ðŸš€ This article was posted in the <a href=https://tech.trivago.com/2020/02/11/better-url-search-with-elasticsearch/>trivago tech blog</a>.</p></blockquote><p>At trivago, we generate a huge amount of logs and we have our <a href=https://tech.trivago.com/2016/01/19/logstash_protobuf_codec/>own custom setup for shipping
logs</a> using mostly <a href=https://developers.google.com/protocol-buffers>Protocol
Buffers</a>. Eventually we end up with some fields in ES
that contain partial (or full) URLs. For instance in our specific case we store the <a href=https://en.wikipedia.org/wiki/URL#Syntax>query
component</a> of the URL in a field called <code>query</code> and the
<a href=https://en.wikipedia.org/wiki/URL#Syntax>path component</a> in a field named <code>url_path</code>. Sample values
for these fields could be:</p><div class=highlight><pre class=chroma><code class=language-sh data-lang=sh><span class=nv>url_path</span> <span class=o>=</span> <span class=s2>&#34;/webservice/search/hotels/43326/rates&#34;</span>
<span class=nv>query</span> <span class=o>=</span> <span class=s2>&#34;from_date=2020-06-01T00:00:00%2B02:00&amp;to_date=2020-06-10T00:00:00%2B02:00&amp;currency=EUR&amp;room_type=9&amp;room_0=2a&amp;fixed_status=1&#34;</span>
</code></pre></div><p>We use the ELK stack as the core of our logging pipeline. Since Elasticsearch&rsquo;s primary use-case was that of a search engine, it comes equipped with a diverse assortment of tools to process data. Searching on
these URL-like texts is not the same as trying to search in a summary of a book. When a field is
defined as <code>text</code> in ES, it will apply by default the <a href=https://www.elastic.co/guide/en/elasticsearch/reference/current/analysis-standard-analyzer.html>Standard
Analyzer</a>.</p><p>The Standard Analyzer uses the <a href=https://www.elastic.co/guide/en/elasticsearch/reference/current/analysis-standard-tokenizer.html>Standard
Tokenizer</a>,
which provides grammar-based tokenization. Put simply: if the value of the field would be an English
sentence written using ASCII characters, the tokenizer will split the text based on punctuation signs,
spaces and some special characters (like <code>/</code> for instance).</p><p>This tokenizer works quite well for our <code>url_path</code> field:</p><div class=highlight><pre class=chroma><code class=language-bash data-lang=bash>POST _analyze
<span class=o>{</span>
 <span class=s2>&#34;tokenizer&#34;</span>: <span class=s2>&#34;standard&#34;</span>,
 <span class=s2>&#34;text&#34;</span>: <span class=s2>&#34;/webservice/search/hotels/43326/rates&#34;</span>
<span class=o>}</span>
</code></pre></div><p>Producing the following list of tokens:</p><div class=highlight><pre class=chroma><code class=language-json data-lang=json><span class=p>[</span> <span class=s2>&#34;webservice&#34;</span><span class=p>,</span> <span class=s2>&#34;search&#34;</span><span class=p>,</span> <span class=s2>&#34;hotels&#34;</span><span class=p>,</span> <span class=s2>&#34;43326&#34;</span><span class=p>,</span> <span class=s2>&#34;rates&#34;</span> <span class=p>]</span>
</code></pre></div><p>If we test the value of the <code>query</code> field against this tokenizer, we can see that it produces a lot
of useless tokens:</p><div class=highlight><pre class=chroma><code class=language-json data-lang=json><span class=p>[</span> <span class=s2>&#34;from_date&#34;</span><span class=p>,</span> <span class=s2>&#34;2020&#34;</span><span class=p>,</span> <span class=s2>&#34;06&#34;</span><span class=p>,</span> <span class=s2>&#34;01T00&#34;</span><span class=p>,</span> <span class=s2>&#34;00&#34;</span><span class=p>,</span> <span class=s2>&#34;00&#34;</span><span class=p>,</span> <span class=s2>&#34;2B02&#34;</span><span class=p>,</span> <span class=s2>&#34;00&#34;</span><span class=p>,</span> <span class=s2>&#34;to_date&#34;</span><span class=p>,</span> <span class=s2>&#34;2020&#34;</span><span class=p>,</span> <span class=s2>&#34;06&#34;</span><span class=p>,</span> <span class=s2>&#34;10T00&#34;</span><span class=p>,</span> <span class=s2>&#34;00&#34;</span><span class=p>,</span> <span class=s2>&#34;00&#34;</span><span class=p>,</span> <span class=s2>&#34;2B02&#34;</span><span class=p>,</span> <span class=s2>&#34;00&#34;</span><span class=p>,</span> <span class=s2>&#34;currency&#34;</span><span class=p>,</span> <span class=s2>&#34;EUR&#34;</span><span class=p>,</span> <span class=s2>&#34;room_type&#34;</span><span class=p>,</span> <span class=s2>&#34;9&#34;</span><span class=p>,</span> <span class=s2>&#34;room_0&#34;</span><span class=p>,</span> <span class=s2>&#34;2a&#34;</span><span class=p>,</span> <span class=s2>&#34;fixed_status&#34;</span><span class=p>,</span> <span class=s2>&#34;1&#34;</span> <span class=p>]</span>
</code></pre></div><p>Although it detected the <code>from_date</code> field, it fails to tokenize the value of the query
parameters as a single token, which makes searching very difficult.</p><p>It is more likely for a user to want to find documents where <code>currency</code> is set to <code>EUR</code> or
<code>room_type</code> equal to <code>9</code>. Generalizing this means that the users are interested in matching on the
key/value pairs present in the query string.</p><p>Let&rsquo;s go over a couple of ways we could approach this.</p><p>We could pre-process the data and make our Logstash pipeline split the data into multiple
fields (using the <a href=https://www.elastic.co/guide/en/logstash/current/plugins-filters-kv.html><code>kv</code> filter</a>
for instance). Creating a new field for each attribute in the query string could lead to a
cardinality explosion in our indexes, even more, considering that any user could create
random key/value pairs.</p><p>We could work around the cardinality issue by flattening the structure and having a couple of nested
fields (<code>name</code> and <code>value</code>):</p><ul><li><code>query.name</code> the field that could hold the attribute name</li><li><code>query.value</code> that would hold the value</li></ul><p>This approach would introduce yet another problem. The <code>query</code> field would have to be an array of objects
and as such, it would lead to queries matching in unexpected ways. Let me explain:</p><p>If we have the following values for our <code>query</code> field (as an array of objects) in a couple of documents:</p><div class=highlight><pre class=chroma><code class=language-json data-lang=json><span class=s2>&#34;query&#34;</span><span class=err>:</span> <span class=p>[</span>
    <span class=p>{</span> <span class=nt>&#34;name&#34;</span><span class=p>:</span><span class=s2>&#34;currency&#34;</span><span class=p>,</span> <span class=nt>&#34;value&#34;</span><span class=p>:</span><span class=s2>&#34;EUR&#34;</span> <span class=p>},</span>
    <span class=p>{</span> <span class=nt>&#34;name&#34;</span><span class=p>:</span><span class=s2>&#34;room_type&#34;</span><span class=p>,</span> <span class=nt>&#34;value&#34;</span><span class=p>:</span><span class=s2>&#34;9&#34;</span> <span class=p>},</span>
<span class=p>]</span>
</code></pre></div><p>A query such as this one:</p><div class=highlight><pre class=chroma><code class=language-js data-lang=js><span class=nx>query</span><span class=p>.</span><span class=nx>name</span><span class=o>:</span><span class=s2>&#34;currency&#34;</span> <span class=nx>AND</span> <span class=nx>query</span><span class=p>.</span><span class=nx>value</span><span class=o>:</span><span class=s2>&#34;9&#34;</span>
</code></pre></div><p>would match our sample document although it would be matching for the <em>&ldquo;wrong reasons&rdquo;</em>. In our
example, <code>currency</code> doesn&rsquo;t have a value of <code>9</code>, but since both boolean conditions are evaluated as
<code>true</code>, the given document would produce a match. It is more likely that the user firing this query
wants to match on <code>currency</code> having the value <code>9</code> which <em>should not</em> produce any matches in our sample
data.</p><h2 id=our-solution>Our solution</h2><p>Since our end goal is to match by attribute name/value pair, if we could make these pairs a <strong>single
token</strong>, we would accomplish our goal with the benefit of having a single field and not strange
matches. With this approach, each key/value pair of the query string would be a single
token in the form of <code>name1=value1</code> and <code>name2=value2</code>. This means that then we could write a query
like:</p><div class=highlight><pre class=chroma><code class=language-js data-lang=js><span class=nx>query</span><span class=o>:</span><span class=s2>&#34;currency=EUR&#34;</span>
</code></pre></div><p>This changes how we can query the data, but it guarantees that it would not produce false matches.
Since we don&rsquo;t generate new fields dynamically, there is also no risk of having cardinality issues.</p><p>The tokenization can be implemented in different places in the pipeline. Using the <a href=https://www.elastic.co/guide/en/logstash/current/plugins-filters-split.html>split
filter</a> or the
previously mentioned <a href=https://www.elastic.co/guide/en/logstash/current/plugins-filters-kv.html>kv
filter</a>. We decided to
use a <a href=https://www.elastic.co/guide/en/elasticsearch/reference/current/analysis-pattern-analyzer.html>custom pattern analyzer</a> on the Elasticsearch side.</p><p>Our <code>pattern_analyzer</code> uses a custom tokenizer defined as:</p><div class=highlight><pre class=chroma><code class=language-json data-lang=json><span class=s2>&#34;url_pattern&#34;</span><span class=err>:</span> <span class=p>{</span>
    <span class=nt>&#34;pattern&#34;</span><span class=p>:</span> <span class=s2>&#34;&amp;&#34;</span><span class=p>,</span>
    <span class=nt>&#34;type&#34;</span><span class=p>:</span> <span class=s2>&#34;pattern&#34;</span>
<span class=p>}</span>
</code></pre></div><p>We also use a custom <code>char_filter</code> to handle the decoding of some special characters into their ASCII
equivalent, which makes the queries more user friendly:</p><div class=highlight><pre class=chroma><code class=language-json data-lang=json><span class=s2>&#34;char_filter&#34;</span><span class=err>:</span> <span class=p>{</span>
    <span class=nt>&#34;url_escape_filter_mapping&#34;</span><span class=p>:</span> <span class=p>{</span>
        <span class=nt>&#34;type&#34;</span><span class=p>:</span> <span class=s2>&#34;mapping&#34;</span><span class=p>,</span>
        <span class=nt>&#34;mappings&#34;</span><span class=p>:</span> <span class=p>[</span>
            <span class=s2>&#34;%20 =&gt; +&#34;</span><span class=p>,</span>
            <span class=s2>&#34;%2B =&gt; +&#34;</span><span class=p>,</span>
            <span class=s2>&#34;%2C =&gt; ,&#34;</span><span class=p>,</span>
            <span class=s2>&#34;%3A =&gt; :&#34;</span><span class=p>,</span>
            <span class=s2>&#34;%5E =&gt; ^&#34;</span><span class=p>,</span>
            <span class=s2>&#34;%7C =&gt; |&#34;</span><span class=p>,</span>
            <span class=s2>&#34;%3D =&gt; =&#34;</span><span class=p>,</span>
            <span class=s2>&#34;%5B =&gt; [&#34;</span><span class=p>,</span>
            <span class=s2>&#34;%5D =&gt; ]&#34;</span>
        <span class=p>]</span>
    <span class=p>}</span>
<span class=p>}</span>
</code></pre></div><p>Finally, we define a custom analyzer called <code>pattern_analyzer</code>:</p><div class=highlight><pre class=chroma><code class=language-json data-lang=json><span class=s2>&#34;pattern_analyzer&#34;</span><span class=err>:</span> <span class=p>{</span>
    <span class=nt>&#34;filter&#34;</span><span class=p>:</span> <span class=p>[</span>
        <span class=s2>&#34;lowercase&#34;</span><span class=p>,</span>
        <span class=s2>&#34;asciifolding&#34;</span><span class=p>,</span>
        <span class=s2>&#34;stop&#34;</span><span class=p>,</span>
        <span class=s2>&#34;unique&#34;</span>
    <span class=p>],</span>
    <span class=nt>&#34;char_filter&#34;</span><span class=p>:</span> <span class=p>[</span>
        <span class=s2>&#34;html_strip&#34;</span><span class=p>,</span>
        <span class=s2>&#34;url_escape_filter_mapping&#34;</span>
    <span class=p>],</span>
    <span class=nt>&#34;type&#34;</span><span class=p>:</span> <span class=s2>&#34;custom&#34;</span><span class=p>,</span>
    <span class=nt>&#34;tokenizer&#34;</span><span class=p>:</span> <span class=s2>&#34;url_pattern&#34;</span>
<span class=p>}</span>
</code></pre></div><p>This analyzer is used in our mapping templates:</p><div class=highlight><pre class=chroma><code class=language-json data-lang=json><span class=s2>&#34;query&#34;</span><span class=err>:</span> <span class=p>{</span>
    <span class=nt>&#34;norms&#34;</span><span class=p>:</span> <span class=kc>false</span><span class=p>,</span>
    <span class=nt>&#34;analyzer&#34;</span><span class=p>:</span> <span class=s2>&#34;pattern_analyzer&#34;</span><span class=p>,</span>
    <span class=nt>&#34;type&#34;</span><span class=p>:</span> <span class=s2>&#34;text&#34;</span>
<span class=p>}</span><span class=err>,</span>
</code></pre></div><p>If we test the initial value of our <code>query</code> field against the field using the custom analyzer:</p><div class=highlight><pre class=chroma><code class=language-bash data-lang=bash>POST accesslogs/_analyze
<span class=o>{</span>
    <span class=s2>&#34;field&#34;</span>: <span class=s2>&#34;query&#34;</span>,
    <span class=s2>&#34;text&#34;</span>: <span class=s2>&#34;from_date=2020-06-01T00:00:00%2B02:00&amp;to_date=2020-06-10T00:00:00%2B02:00&amp;currency=EUR&amp;room_type=9&amp;room_0=2a&amp;fixed_status=1&#34;</span>
<span class=o>}</span>
</code></pre></div><p>We get a more useful list of tokens:</p><div class=highlight><pre class=chroma><code class=language-json data-lang=json><span class=p>[</span> <span class=s2>&#34;from_date=2020-06-01t00:00:00+02:00&#34;</span><span class=p>,</span> <span class=s2>&#34;to_date=2020-06-10t00:00:00+02:00&#34;</span><span class=p>,</span> <span class=s2>&#34;currency=eur&#34;</span><span class=p>,</span> <span class=s2>&#34;room_type=9&#34;</span><span class=p>,</span> <span class=s2>&#34;room_0=2a&#34;</span><span class=p>,</span> <span class=s2>&#34;fixed_status=1&#34;</span> <span class=p>]</span>
</code></pre></div><p>Using this list of tokens, it is easier to find those specific requests that we&rsquo;re looking for. It is
even more intuitive what is going on if we need to share the query with a colleague.</p><div class="info announce"><svg width="320" viewBox="0 0 512 512"><circle cx="256" cy="256" r="246" fill="#ff8c8c"/><circle cx="256" cy="256" r="192" fill="#fff"/><g fill="#7d9bff"><path d="M291 336h-15V236c0-11-9-20-20-20h-28a20 20 0 100 40h8v80h-15a20 20 0 100 40h70a20 20 0 100-40z"/><circle cx="256" cy="156.1" r="20"/></g><path d="M256 512A254 254 0 010 256 254 254 0 01256 0a254 254 0 01256 256 254 254 0 01-256 256zm0-492a236 236 0 101 473 236 236 0 00-1-473z"/><path d="M256 458c-37 0-74-10-106-30a10 10 0 1110-17 182 182 0 10-60-61 10 10 0 01-17 10 203 203 0 0130-247 202 202 0 11143 345z"/><path d="M120 402a10 10 0 117-17 10 10 0 01-7 17zm171-16h-70a30 30 0 010-60h5v-60a30 30 0 012-60h28c17 0 30 14 30 30v90h5a30 30 0 010 60zm-70-40a10 10 0 000 20h70a10 10 0 000-20h-15c-6 0-10-5-10-10V236c0-5-4-10-10-10h-28a10 10 0 000 20h8c6 0 10 5 10 10v80c0 5-4 10-10 10h-15zm35-16086a30 30 0 110-60 30 30 0 010 60zm0-40a10 10 0 100 20 10 10 0 000-20z"/></svg><div>We could&rsquo;ve decided to write our own tokenizer to deal with URLs. It would have provided us with full
control over the Token Stream (i.e tokens) produced by Elasticsearch. Still, dealing with custom
analyzers involves writing and maintaining custom plugins, which would have been definitively more
difficult to support in the long run. Instead, we chose to leverage the already quite flexible
toolbox provided by Elasticsearch.</div></div><h2 id=thanks>Thanks</h2><p>I want to thank my colleague <a href=https://github.com/unidario>ðŸ¦„ Dario Segger</a> (currently ex-teammate)
that did the implementation described in this post. We&rsquo;ve been using this approach for some time now.</p></section></article><footer id=post-meta class=clearfix><svg class="avatar" width="50" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path fill="#cbd5e0" d="M20.3 12.04l1.01 3a1 1 0 01-1.26 1.27l-3.01-1a7 7 0 113.27-3.27zM11 10a1 1 0 100-2 1 1 0 000 2zm3 0a1 1 0 100-2 1 1 0 000 2zm3 0a1 1 0 100-2 1 1 0 000 2z"/><path fill="#4a5568" d="M15.88 17.8a7 7 0 01-8.92 2.5l-3 1.01a1 1 0 01-1.27-1.26l1-3.01A6.97 6.97.0 015 9.1a9 9 0 0010.88 8.7z"/></svg><a href=https://twitter.com/jorgelbg><div><span class=dark>Want to leave a comment?</span>
<span>Drop me a message on Twitter @jorgelbg</span></div></a><section id=sharing><a class=twitter target=_blank href="https://twitter.com/intent/tweet?text=%2f%2fjorgelbg.me%2f2020%2f01%2fbetter-url-search-with-elasticsearch%2f - Better%20URL%20search%20with%20Elasticsearch by @jorgelbg"><span class=icon-twitter>tweet</span></a></section></footer><ul id=post-list class="archive readmore"><h3>Read more</h3><li><a href=//jorgelbg.me/2021/08/introducing-pinentry-touchid/><span>Introducing pinentry-touchid</span><aside class=dates>Aug 3 2021</aside></a></li><li><a href=//jorgelbg.me/2020/03/displaying-geohash-tags-from-a-loki-datasource-in-a-grafana-worldmap-panel/><span>Displaying geohash tags from a Loki datasource in a Grafana Worldmap Panel</span><aside class=dates>Mar 18 2020</aside></a></li><li><a href=//jorgelbg.me/2020/02/web-ui-for-testing-dissect-patterns/><span>Web UI for testing dissect patterns</span><aside class=dates>Feb 21 2020</aside></a></li></ul><footer id=footer><p class=small>Â© Copyright 2021 Jorge Luis Betancourt</p><p class="small cc">Icons made by
<a href=https://www.freepik.com/ title=Freepik>Freepik</a> from
<a href=https://www.flaticon.com/ title=Flaticon>www.flaticon.com</a> is
licensed by
<a href=https://creativecommons.org/licenses/by/3.0/ title="Creative Commons BY 3.0" target=_blank>CC 3.0 BY</a></p></footer></section><script type=application/javascript>var doNotTrack=false;if(!doNotTrack){(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');ga('create','UA-115201846-1','auto');ga('send','pageview');}</script></body></html>