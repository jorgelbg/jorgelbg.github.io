<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Jorge Luis Betancourt</title><link>//jorgelbg.me/</link><description>Recent content on Jorge Luis Betancourt</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Wed, 18 Mar 2020 00:00:00 +0100</lastBuildDate><atom:link href="//jorgelbg.me/index.xml" rel="self" type="application/rss+xml"/><item><title>Displaying geohash tags from a Loki datasource in a Grafana Worldmap Panel</title><link>//jorgelbg.me/2020/03/displaying-geohash-tags-from-a-loki-datasource-in-a-grafana-worldmap-panel/</link><pubDate>Wed, 18 Mar 2020 00:00:00 +0100</pubDate><guid>//jorgelbg.me/2020/03/displaying-geohash-tags-from-a-loki-datasource-in-a-grafana-worldmap-panel/</guid><description>Loki is a new~ish project from Grafana, yes the same company behind the popular open-source observability platform. Loki itself is a horizontally-scalable, highly-available, multi-tenant log aggregation system inspired by Prometheus.
On fewer words, Loki is like Prometheus but for your logs. This means that although it doesn't provide all the full-text search capabilities of Elasticsearch, it allows filtering by a set of labels for each log stream. This translates into a more cost-effective solution.</description></item><item><title>Web UI for testing dissect patterns</title><link>//jorgelbg.me/2020/02/web-ui-for-testing-dissect-patterns/</link><pubDate>Fri, 21 Feb 2020 10:49:32 +0100</pubDate><guid>//jorgelbg.me/2020/02/web-ui-for-testing-dissect-patterns/</guid><description>If you have been using Filebeat to ship your logs around (usually to Elasticsearch) you know that Filebeat doesn't support Grok patterns (like Logstash does). Instead, Filebeat advocates the usage of the dissect processor.
A small CLI tool for local pattern testing is also available now. Releases are available in the Github Releases page. After downloading and decompressing the .tar.gz file the CLI can be executed as:</description></item><item><title>Better URL search with Elasticsearch</title><link>//jorgelbg.me/2020/01/better-url-search-with-elasticsearch/</link><pubDate>Wed, 01 Jan 2020 11:46:14 -0500</pubDate><guid>//jorgelbg.me/2020/01/better-url-search-with-elasticsearch/</guid><description>üöÄ This article has been crossposted in the trivago tech blog.
At trivago, we generate a huge amount of logs and we have our own custom setup for shipping logs using mostly Protocol Buffers. Eventually we end up with some fields in ES that contain partial (or full) URLs. For instance in our specific case we store the query component of the URL in a field called query and the path component in a field named url_path.</description></item><item><title>How to rename index patterns in Kibana</title><link>//jorgelbg.me/2019/05/how-to-rename-index-patterns-in-kibana/</link><pubDate>Tue, 21 May 2019 17:00:00 +0200</pubDate><guid>//jorgelbg.me/2019/05/how-to-rename-index-patterns-in-kibana/</guid><description>If you have been using Kibana long enough you probably have a large collection of visualizations and dashboards already created. From time to time you may have a need to rename an already index pattern. Turns out that Kibana doesn't support this. You can refresh the index pattern and you can drop it but that's it. There is an [open issue in Github] (https://github.com/elastic/kibana/issues/17542) to address this issue, but it is still open at the time of writing this post.</description></item><item><title>Useful alerts with Elastic Watcher &amp; Machine Learning</title><link>//jorgelbg.me/2019/03/useful-alerts-with-elastic-watcher-machine-learning/</link><pubDate>Fri, 15 Mar 2019 13:00:00 +0100</pubDate><guid>//jorgelbg.me/2019/03/useful-alerts-with-elastic-watcher-machine-learning/</guid><description>Alerts should be meaningful, simply getting a notification about something happening is not enough. A good alert should be actionable and investigable. For me, this means getting a answer to the following questions:
What happened? Was the traffic to the Web site unusually low? Did the number of errors increase? This is the type of information that the alert should contain in a clear and visible way.
Why an alert triggered?</description></item><item><title>Display the application's version in your Grafana dashboards</title><link>//jorgelbg.me/2019/02/display-the-applications-version-in-your-grafana-dashboards/</link><pubDate>Sun, 17 Feb 2019 14:00:28 +0100</pubDate><guid>//jorgelbg.me/2019/02/display-the-applications-version-in-your-grafana-dashboards/</guid><description>At work, we needed a way to monitor the lag of some Kafka consumers reading business-critical topics.
We ended up using this exporter that provided exactly the metrics that we needed. After adding metadata caching to reduce the load on our Kafka cluster we deployed the exporter to our Nomad cluster and started to build dashboards.
While I was making changes to the application. I needed not only to check the logs but also to graph the data that the exporter was getting from Kafka, to make sure that my changes were not breaking the normal behavior.</description></item><item><title>Optimize Grafana dashboards with Elasticsearch index aliases</title><link>//jorgelbg.me/2018/12/optimize-grafana-dashboards-with-elasticsearch-index-aliases/</link><pubDate>Thu, 20 Dec 2018 00:00:00 +0100</pubDate><guid>//jorgelbg.me/2018/12/optimize-grafana-dashboards-with-elasticsearch-index-aliases/</guid><description>Grafana is a very popular opensource dashboarding solution. Provides support for a long list of storage solutions, including Elasticsearch. Unfortunately, the ES support is not at the same level as the one you get for InfluxDB, for instance. Still, Grafana allows combining in the same dashboard different data sources. It is possible to have a panel fetching data from ES and a different panel fetching data from InfluxDB.
Grafana ‚ù§Ô∏è Elasticsearch Grafana provides stellar support for InfluxDB &amp;amp; Prometheus, among others.</description></item><item><title>Logs and metrics for Small Data</title><link>//jorgelbg.me/2018/08/logs-and-metrics-for-small-data/</link><pubDate>Thu, 23 Aug 2018 05:42:44 +0200</pubDate><guid>//jorgelbg.me/2018/08/logs-and-metrics-for-small-data/</guid><description>This post is a personal comment. I'm going to talk about how using some tools thought for &amp;ldquo;Big Data&amp;quot;‚Ñ¢ makes sense for common development tasks. If you hear someone talking about ELK, Grafana or Prometheus, you wouldn't think about a system to run your laptop during development, right?
Logs Concatenating files, parsing logs, are some of those tasks that are part of our daily routine as developers. We type lots of commands (usually connected via pipes |) to accomplish a given goal.</description></item><item><title>Solr Contextual Synonyms with Payloads</title><link>//jorgelbg.me/2018/03/solr-contextual-synonyms-with-payloads/</link><pubDate>Tue, 06 Mar 2018 01:00:00 +0100</pubDate><guid>//jorgelbg.me/2018/03/solr-contextual-synonyms-with-payloads/</guid><description>Solr comes with a great set of tools to dealing with usual text processing tasks. One of this tools is the SynonymFilterFactory which allow to specify a list of synonyms. Last year we saw some improvements to this feature, focused around multi word synonyms. Even with the new changes introduced in Solr there are still some caveats, as explained by Doug on this post. To be honest this was developed some time ago, back when Solr 5 was the &amp;ldquo;cool&amp;rdquo; new version üòÅ.</description></item></channel></rss>