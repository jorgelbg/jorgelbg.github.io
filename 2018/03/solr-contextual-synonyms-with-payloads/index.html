<!DOCTYPE html>
<html lang="en-us">
	<head>
    <meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="author" content="Jorge Luis Betancourt">
<meta name="description" content="Computo Ergo Sum">
<meta name="generator" content="Hugo 0.54.0" />
<title>Solr Contextual Synonyms with Payloads</title>
<link rel="shortcut icon" href="http://jorgelbg.github.io/images/favicon.ico">
<link rel="stylesheet" href="http://jorgelbg.github.io/css/style.css">
<link rel="stylesheet" href="http://jorgelbg.github.io/css/highlight.css">

<link rel="stylesheet" href="http://jorgelbg.github.io/css/custom.css">



<link href="http://jorgelbg.github.io/index.xml" rel="alternate" type="application/rss+xml" title="Jorge Luis Betancourt" />


<meta property="og:title" content="Solr Contextual Synonyms with Payloads" />
<meta property="og:description" content="A different approach for contextual synonyms with Apache Solr using the term payload" />
<meta property="og:type" content="article" />
<meta property="og:url" content="http://jorgelbg.github.io/2018/03/solr-contextual-synonyms-with-payloads/" />
<meta property="article:published_time" content="2018-03-06T01:00:00&#43;01:00"/>
<meta property="article:modified_time" content="2018-03-06T01:00:00&#43;01:00"/>



<meta itemprop="name" content="Solr Contextual Synonyms with Payloads">
<meta itemprop="description" content="A different approach for contextual synonyms with Apache Solr using the term payload">


<meta itemprop="datePublished" content="2018-03-06T01:00:00&#43;01:00" />
<meta itemprop="dateModified" content="2018-03-06T01:00:00&#43;01:00" />
<meta itemprop="wordCount" content="2311">



<meta itemprop="keywords" content="" />

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Solr Contextual Synonyms with Payloads"/>
<meta name="twitter:description" content="A different approach for contextual synonyms with Apache Solr using the term payload"/>
<meta name="twitter:site" content="@https://www.twitter.com/jorgelbgm"/>


    </head>
<body>
    <nav class="main-nav">
	
		<a href='http://jorgelbg.github.io/'>
			<svg height="30" fill="#5661B3" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 492 492"><path d="M464.344 207.418l.768.168H135.888l103.496-103.724c5.068-5.064 7.848-11.924 7.848-19.124 0-7.2-2.78-14.012-7.848-19.088L223.28 49.538c-5.064-5.064-11.812-7.864-19.008-7.864-7.2 0-13.952 2.78-19.016 7.844L7.844 226.914C2.76 231.998-.02 238.77 0 245.974c-.02 7.244 2.76 14.02 7.844 19.096l177.412 177.412c5.064 5.06 11.812 7.844 19.016 7.844 7.196 0 13.944-2.788 19.008-7.844l16.104-16.112c5.068-5.056 7.848-11.808 7.848-19.008 0-7.196-2.78-13.592-7.848-18.652L134.72 284.406h329.992c14.828 0 27.288-12.78 27.288-27.6v-22.788c0-14.82-12.828-26.6-27.656-26.6z"/></svg>
			
		</a>
	

	

	
</nav>

    <section id="wrapper">
        
        
<article class="post">
    <header>
        <h1>Solr Contextual Synonyms with Payloads</h1>
        <h2 class="headline">
            March 6, 2018
            <br>
            
        </h2>
    </header>
    <section id="post-body">
        

<p>Solr comes with a great set of tools to dealing with usual text processing tasks. One of this tools is the <code>SynonymFilterFactory</code> which allow to specify a list of synonyms. Last year we saw some <a href="https://lucidworks.com/2017/04/18/multi-word-synonyms-solr-adds-query-time-support/">improvements to this feature</a>, focused around multi word synonyms.
Even with the new changes introduced in Solr there are still some caveats, as explained by <a href="https://opensourceconnections.com/blog/2018/02/20/edismax-and-multiterm-synonyms-oddities/">Doug on this post</a>. To be honest this was developed some time ago, back when Solr 5 was the &ldquo;cool&rdquo; new version üòÅ.</p>

<p>This post describes a component to index token synonyms as a payload. Instead of a big file, you send the synonym as a payload for the desired token. This approach works great for single term synonyms, specifying the synonyms at index time. If you&rsquo;re curious about how this works, then continue reading.</p>

<h2 id="a-bit-of-history">A bit of history</h2>

<p>Some time ago I suggested a similar approach in this <a href="https://stackoverflow.com/questions/34122982/lucene-solr-store-offset-information-for-certain-keywords">question, posted on stackoverflow.com</a>. A user was asking to store positional information about the tokens. The end goal was to define something that we could call &ldquo;contextual synonyms&rdquo;.</p>

<blockquote>
<p>Contextual synonym: a single term can relate to different concepts in the same text.</p>
</blockquote>

<p>For instance, if we take a look at the following sentence: <code>Bill talked to the white house about the bill</code>. The first occurrence of <code>Bill</code> could be a reference to  <code>Bill Clinton</code>. While the second appearance of <code>bill</code> relates to some law<sup>1</sup>. One business rule could be that a query with the term <code>Clinton</code> should match this document. I know, I know I&rsquo;m doing a lot of assumptions, but bear with me until the end. If we use the traditional synonym mechanism built in Solr, then we may set up a synonym like:</p>

<pre><code>bill =&gt; clinton
</code></pre>

<blockquote>
<p>Figuring out to which tokens apply the synonym is out of the scope of this post.</p>
</blockquote>

<p>Let&rsquo;s assume that we&rsquo;re using the <code>LowerCaseFilterFactory</code>. Solr doesn&rsquo;t know how to differentiate between the two occurrences of <code>bill</code>. We need some mechanism to tell Solr that <code>clinton</code> is also a synonym of only the <strong>first</strong> occurrence of <code>bill</code>. In short, this query: <code>&quot;clinton talked&quot;</code> should then match our document, but not this one <code>&quot;about clinton&quot;</code>.</p>

<p>Solr doesn&rsquo;t provide an out-of-the-box approach for deciding when to apply or not a synonym. But using some Lucene/Solr sauce we can do it. Lucene stores  some positional information for each token. What we want is to have some mechanism to adding the synonym only for certain tokens. Turns out that Lucene already provides a way to attach some &ldquo;metadata&rdquo; to a token: a payload. This <em>payload</em> could be anything that we want. It&rsquo;s encoded as an array of <code>bytes</code> (<code>bytes[]</code>). Solr exposes this feature as a <code>TokenFilter</code> that uses a delimiter to split the token from the payload. We also have access to several encoders (<code>FloatEncoder</code>, <code>IntegerEncoder</code>, <code>IdentityEncoder</code>) to store <code>floats</code>, <code>integers</code>, and <code>strings</code>.</p>

<p>In Solr indexing payloads is very easy, in this case we&rsquo;re using the (<code>|</code>) pipe character as the delimiter.</p>

<pre><code class="language-xml">&lt;filter class=&quot;solr.DelimitedPayloadTokenFilterFactory&quot; delimiter=&quot;|&quot; encoder=&quot;identity&quot;/&gt;
</code></pre>

<p>Any token in the form of <code>A|B</code> sent to Solr will be interpreted as token <code>A</code> with payload <code>B</code>. The <code>DelimitedPayloadTokenFilterFactory</code> will remove <code>|B</code> from the token before sending it down the analysis chain. If we send the following into Solr:</p>

<pre><code>Bill|Clinton talked to the white house about the bill
</code></pre>

<p><code>Clinton</code> will be stored as the payload of the <code>Bill</code> token and the later <code>bill</code> will remain unchanged.</p>

<p>This doesn&rsquo;t solve our problem, but we&rsquo;re on track, so far we&rsquo;ve found a way to send custom tokens (synonyms) into Solr. The <em>payload</em> metadata is usually <a href="https://lucidworks.com/blog/2014/06/13/end-to-end-payload-example-in-solr/">used to influence the score calculation</a>. We&rsquo;re going to write our own <code>TokenFilter</code> that reads the payload and will add it to the token stream.</p>

<p>This should be a more straight forward synonym implementation. We don&rsquo;t need to parse any rule to find which synonym to use, and we already know <em>where</em> and <em>what</em> token to add.</p>

<!-- This token filter will be a lot easier than the existing implementation, mainly because no rule parsing of a file and no guessing which rule apply to each token is needed; of course it will be also less powerful, since we're talking about a synonym to a **token** we don't have the ability to define a multiword synonym. For instance using `SynonymFilterFactory` we could specify the following synonym:

```
domain name server => dns
```

In each occurrence of `domain name server`, the synonym will be used. With our implementation this wouldn't be possible because we're attaching each synonym in the corresponding token, so the current token doesn't know about the previous/next tokens. -->

<h2 id="the-code">The code</h2>

<p>Now we know what we need to write, so let&rsquo;s doit.</p>

<p>Writing a <code>TokenFilter</code> is not that hard, but of course depends on the task at hand. We need a class that extends from <code>TokenFilter</code>  and overrides the <code>incrementToken()</code> method. As described on JavaDoc:</p>

<blockquote>
<p>This method is used to advance the stream to the next token and should return <code>false</code> for the end of the stream of tokens and <code>true</code> otherwise.</p>
</blockquote>

<p>Our custom filter will access the term&rsquo;s payload using the  <code>PayloadAttribute</code> class. This property will provide read/write access to the payload of the current term. The API around the token stream is an iterator, and each call to <code>incrementToken()</code> will advance to the next token.</p>

<p>Suppose we send the following document into solr: <code>A B|E C</code>, what we&rsquo;re trying to say is that <code>E</code> is a synonym of <code>B</code>. This means that phrase queries should continue to work as expected. Bottom line we need our method to output a token graph (Yes! Token streams in Lucene are graphs‚ÄºÔ∏è) like this:</p>

<pre><code class="language-json">(A0) ----&gt; (B1) ----&gt; (C2)
  \                  /
    -----&gt; (E1) ----
</code></pre>

<p>Actually, the previous graph is not an exact representation of a <code>TokenStream</code>. If we&rsquo;re going to get serious the graph will look more like this:</p>

<pre><code class="language-json">       A          B          C
(0)  -----&gt; (1) -----&gt; (2) -----&gt; (3)
               \      /
                -----  
                  E
</code></pre>

<p>The tokens are placed in the edges of the graph and the nodes are the states/positions of the token. But for our task at hand we can rely on the first graph for an easier representation.</p>

<p>So <code>B</code> and <code>E</code> should have the same position in the token graph (1). A phrase query like: <code>&quot;B C&quot;</code> will match our document, but also <code>&quot;E C&quot;</code> or <code>&quot;A E&quot;</code>. To do this we&rsquo;ll need to use the <code>PositionIncrementAttribute</code> class. The code for our <code>incrementToken()</code> method is roughly something like:</p>

<pre><code class="language-java">if (!extraTokens.isEmpty()) {
  restoreState(state);

  posIncrAtt.setPositionIncrement(0); // keep the same position of the token
  typeAtt.setType(SynonymFilter.TYPE_SYNONYM);
  termAtt.setEmpty().append(extraTokens.remove());

  return true;
}

if (input.incrementToken()) {
  BytesRef payload = payAtt.getPayload();

  extraTokens.add(payload.utf8ToString());
  state = captureState();

  return true;
}

return false;
}
</code></pre>

<p>The <code>incrementToken()</code> method returns the metadata for the next token. Because of this, we need to save the state of the attributes to &ldquo;insert&rdquo; the  synonym in the right position. Also the position increment needs to be set to 0 or the term will be in the wrong position.</p>

<p>Our implementation detects the token with a payload and in the next call we add the payload as a new token. In the final implementation we do a couple more of things:</p>

<ul>
<li>remove the payload (since we don&rsquo;t need it anymore)</li>
<li>split the payload using a delimiter character to generate several synonyms</li>
</ul>

<h2 id="testing">Testing</h2>

<p>How do we test that our implementation is working as intended? At this stage you may compile your project, generate a jar and add it to Solr and hope that all works well.</p>

<p>The best approach for testing our implementation is writing a Unit Test. Thanks to the amazing committers and community, Lucene already ships with <code>BaseTokenStreamTestCase</code>. A base class that provides several helper methods for testing.</p>

<p>But what do we want to test?</p>

<p>To &ldquo;glue&rdquo; everything in Solr, we need the <code>solr.DelimitedPayloadTokenFilterFactory</code> to index tokens and payloads. But this class is already tested in the Lucence/Solr codebase. For testing our custom filter we need tokens with payloads attached. Let&rsquo;s write a dummy <code>TokenFilter</code> that will provide us with a proper stream of tokens with payloads.</p>

<pre><code class="language-java">private final class DummyPayloadTokenFilter extends TokenFilter {
  private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class);
  private final PayloadAttribute payAtt = addAttribute(PayloadAttribute.class);

  private final List&lt;String&gt; payloadTokens = Arrays.asList(&quot;A&quot;, &quot;B&quot;, &quot;C&quot;);
  private final PayloadEncoder encoder = new IdentityEncoder();
  private final BytesRef payload;

  private DummyPayloadTokenFilter(TokenStream input) {
    super(input);
    this.payload = encoder.encode(&quot;D&quot;.toCharArray());
  }

  private DummyPayloadTokenFilter(TokenStream input, String payloadValue) {
    super(input);
    this.payload = encoder.encode(payloadValue.toCharArray());
  }

  @Override
  public boolean incrementToken() throws IOException {
    if (input.incrementToken()) {
      if (payloadTokens.contains(termAtt.toString())) payAtt.setPayload(payload);
      return true;
    } else {
      return false;
    }
  }
}
</code></pre>

<p>With this dummy <code>TokenFilter</code> we can wrap a mock of a <code>TokenStream</code> and feed it into our <code>PayloadSynonymTokenFilter</code> and test our custom logic.</p>

<p>Now to the next item, how do we test a <code>TokenFilter</code>? We need to start with a string (<code>A B C</code>), which needs to converted into a <code>TokenStream</code>. For this we can use the handy helper method <code>whitespaceMockTokenizer()</code>. This methods will tokenize the string at any occurrence of a whitespace character. Once we have an actual <code>TokenStream</code> to feed to our filter we can start writting assertions.</p>

<p>We need to call <code>incrementToken()</code> and at each step check if the current term is correct and if any other term attribute (such as our beloved payload) has also the expected value.</p>

<p>This assertions are not hard to write. Peeking around the Lucene test suite I came across this handy method than resembled a lot to what I was writing. I decided to use it instead (no harm no fall).</p>

<pre><code class="language-java">void assertTermEquals(String expected, TokenStream stream, CharTermAttribute termAtt, PayloadAttribute payAtt,
    byte[] expectPay) throws Exception {
  assertTrue(stream.incrementToken());
  assertEquals(expected, termAtt.toString());
  BytesRef payload = payAtt.getPayload();

  if (payload != null) {
    assertTrue(payload.length + &quot; does not equal: &quot; + expectPay.length, payload.length == expectPay.length);
    for (int i = 0; i &lt; expectPay.length; i++) {
      assertTrue(expectPay[i] + &quot; does not equal: &quot; + payload.bytes[i + payload.offset],
          expectPay[i] == payload.bytes[i + payload.offset]);
    }
  } else {
    assertTrue(&quot;expectPay is not null and it should be&quot;, expectPay == null);
  }
}
</code></pre>

<p>Using this method our test code is a series of calls to <code>assertTermEquals</code> passing the right arguments.</p>

<p>Let&rsquo;s go back to our initial test string. Assuming that only the <code>A</code> token carries a payload, our expected <code>TokenStream</code> should look like <code>A D B C</code>.  <code>D</code> should be a synonym of <code>A</code>: both <code>A</code> and <code>D</code> should have the same position in the stream. The test would look something like:</p>

<pre><code class="language-java">@Test
public void testSingleSynonym() throws Exception {
  String test = &quot;A B C&quot;;

  PayloadSynonymTokenFilter filter = new PayloadSynonymTokenFilter(
    new DummyPayloadTokenFilter(whitespaceMockTokenizer(test)),
    false, false, &quot;_&quot;
  );

  CharTermAttribute termAtt = filter.getAttribute(CharTermAttribute.class);
  PayloadAttribute payAtt = filter.getAttribute(PayloadAttribute.class);

  filter.reset();

  assertTermEquals(&quot;A&quot;, filter, termAtt, payAtt,
    &quot;D&quot;.getBytes(StandardCharsets.UTF_8)
  );
  assertTermEquals(&quot;D&quot;, filter, termAtt, payAtt,
    &quot;D&quot;.getBytes(StandardCharsets.UTF_8)
  );
  assertTermEquals(&quot;B&quot;, filter, termAtt, payAtt, null);
  assertTermEquals(&quot;C&quot;, filter, termAtt, payAtt, null);
  assertFalse(filter.incrementToken());

  filter.end();
  filter.close();
}
</code></pre>

<p>For the <code>A</code> and <code>D</code> tokens we&rsquo;re also checking that the payload is still there (since we haven&rsquo;t removed it yet), but for <code>B</code> and <code>C</code> there should be no payload at all, so we pass a <code>null</code> parameter to validate this assumption.</p>

<p>Its important to check that the filter returns <code>false</code> when it reaches the end of the <code>TokenStream</code>.</p>

<p>There is still something missing in our test. Let&rsquo;s go back to the couple of figures at the beginning of the post, where we represent the <code>TokenStream</code> as a graph. In those graphs we can see that the token and the synonym should have the same <strong>positional information</strong>. In other words, both terms should be at the same position within the token stream. Or, said in the &ldquo;Lucene jargon&rdquo; the position increment of the synonym should be <code>0</code>. To check this in our test we need to use the <code>PositionIncrementAttribute</code> class:</p>

<pre><code class="language-java">PositionIncrementAttribute posIncAtt =
    filter.getAttribute(PositionIncrementAttribute.class);

assertEquals(0, posIncAtt.getPositionIncrement());
</code></pre>

<p>The default position increment for the rest of the <code>TokenStream</code> should be 1, which we could also test.</p>

<p>Lucene use &ldquo;attributes&rdquo; to store information about a single token. Instead of storing the actual position of a term, Lucene stores the increment of each token. This <code>increment</code> is then used to figure out the actual position of the token in the stream. We can see this information in the analysis page of the Solr Admin UI. This is the internal mechanism that Lucene uses for phrase search and span queries, etc.</p>

<h2 id="using-in-solr">Using in Solr</h2>

<p>The entire code of this example is available in this <a href="https://github.com/jorgelbg/solr-payload-synonyms">Github repo</a>. You can build it using maven and then enable it in your Solr/Fusion installation as a normal filter:</p>

<pre><code class="language-xml">&lt;fieldtype name=&quot;payloads&quot; stored=&quot;false&quot; indexed=&quot;true&quot; class=&quot;solr.TextField&quot; &gt;
 &lt;analyzer&gt;
   &lt;tokenizer class=&quot;solr.WhitespaceTokenizerFactory&quot;/&gt;
   &lt;filter class=&quot;solr.DelimitedPayloadTokenFilterFactory&quot; delimiter=&quot;|&quot; encoder=&quot;identity&quot;/&gt;
   &lt;filter class=&quot;solr.custom.PayloadSynonymTokenFilterFactory&quot;/&gt;
 &lt;/analyzer&gt;
&lt;/fieldtype&gt;
</code></pre>

<p>Once our <code>fieldtype</code> is defined we can use the very helpful Analysis page of the Solr Admin UI to check if things are working as expected. If we use the test string: <code>Bill|Clinton talked about the bill</code> in the Field value (index) input and select our payload <code>fieldtype</code> we can see an output similar to what is shown in the figure.</p>

<p><img src="/images/solr-synonyms/analysis-ui.png" alt="Solr Admin UI" title="Solr Admin UI" /></p>

<p>A quick inspection, reveals that the tokens <code>Bill</code> and <code>Clinton</code> have the same positional information. Also the <code>Clinton</code> token has a defined type of <code>SYNONYM</code>.</p>

<h2 id="advantages-to-this-approach">Advantages to this approach?</h2>

<p>One question you may been doing yourself is what advantages provides this approach?</p>

<p>This approach <em>decentralizes</em> the synonyms management. Usually your synonyms live in a big text file on the filesystem of your Solr server. Adding new synonyms  means editing that file and adding a new rule.</p>

<p>In recent Solr versions, the <code>ManagedSynonymFilterFactory</code> class provides an HTTP endpoint to do this. But it is not a good idea to give everyone on your team access to this endpoints. I used this approach in a cloud-like environment for Solr. We provided Solr as a service to different teams with different needs. Along with the service we provided our own utility library for interacting with Solr.  In this library we did the heavy lifting and exposed a clean and easy API for the developers.</p>

<p>In this environment this approach gave control over the synonyms to each developer. They could customize their synonyms  without knowing the inner workings of Solr.</p>

<p>And of course this solves part of our initial statement: tailoring  a synonym to a specific term/token.</p>

<p>To wrap things up this has been a fun exercise and an atypical use of Lucene/Solr payloads. If it is useful to you then use it if not I hope you&rsquo;ve enjoyed the reading, I&rsquo;ve enjoyed the journey!</p>

    </section>
</article>

<footer id="post-meta" class="clearfix">
    <a href="https://twitter.com/jorgelbg">
    <img class="avatar" src="http://jorgelbg.github.io/images/avatar.png">
    <div>
        <span class="dark">Jorge Luis Betancourt</span>
        <span>Software engineer with a passion for data, search and performance</span>
    </div>
    </a>
    <section id="sharing">
        <a class="twitter" href="https://twitter.com/intent/tweet?text=http%3a%2f%2fjorgelbg.github.io%2f2018%2f03%2fsolr-contextual-synonyms-with-payloads%2f - Solr%20Contextual%20Synonyms%20with%20Payloads by @jorgelbg"><span class="icon-twitter"> tweet</span></a>

<a class="facebook" href="#" onclick="
    window.open(
      'https://www.facebook.com/sharer/sharer.php?u='+encodeURIComponent(location.href),
      'facebook-share-dialog',
      'width=626,height=436');
    return false;"><span class="icon-facebook-rect"> Share</span>
</a>

    </section>
</footer>



<ul id="post-list" class="archive readmore">
    <h3>Read more</h3>

    
    
    
        <li>
            <a href="/2019/03/useful-alerts-with-elastic-watcher-machine-learning/">Useful alerts with Elastic Watcher &amp; Machine Learning<aside class="dates">Mar 15 2019</aside></a>
        </li>
    
        <li>
            <a href="/2019/02/display-the-applications-version-in-your-grafana-dashboards/">Display the application&#39;s version in your Grafana dashboards<aside class="dates">Feb 17 2019</aside></a>
        </li>
    
        <li>
            <a href="/2018/12/optimize-grafana-dashboards-with-elasticsearch-index-aliases/">Optimize Grafana dashboards with Elasticsearch index aliases<aside class="dates">Dec 20 2018</aside></a>
        </li>
    
        <li>
            <a href="/2018/08/logs-and-metrics-for-small-data/">Logs and metrics for Small Data<aside class="dates">Aug 23 2018</aside></a>
        </li>
    
</ul>



        <footer id="footer">
    
        <div id="social">
    
    <a class="symbol github" href="https://github.com/jorgelbg">
    
        <svg height="30" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path d="M255.968 5.329C114.624 5.329 0 120.401 0 262.353c0 113.536 73.344 209.856 175.104 243.872 12.8 2.368 17.472-5.568 17.472-12.384 0-6.112-.224-22.272-.352-43.712-71.2 15.52-86.24-34.464-86.24-34.464-11.616-29.696-28.416-37.6-28.416-37.6-23.264-15.936 1.728-15.616 1.728-15.616 25.696 1.824 39.2 26.496 39.2 26.496 22.848 39.264 59.936 27.936 74.528 21.344 2.304-16.608 8.928-27.936 16.256-34.368-56.832-6.496-116.608-28.544-116.608-127.008 0-28.064 9.984-51.008 26.368-68.992-2.656-6.496-11.424-32.64 2.496-68 0 0 21.504-6.912 70.4 26.336 20.416-5.696 42.304-8.544 64.096-8.64 21.728.128 43.648 2.944 64.096 8.672 48.864-33.248 70.336-26.336 70.336-26.336 13.952 35.392 5.184 61.504 2.56 68 16.416 17.984 26.304 40.928 26.304 68.992 0 98.72-59.84 120.448-116.864 126.816 9.184 7.936 17.376 23.616 17.376 47.584 0 34.368-.32 62.08-.32 70.496 0 6.88 4.608 14.88 17.6 12.352C438.72 472.145 512 375.857 512 262.353 512 120.401 397.376 5.329 255.968 5.329z"/></svg>
    
    </a>
    
    <a class="symbol twitter" href="https://www.twitter.com/jorgelbgm">
    
        <svg height="30" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 612 612"><path d="M612 116.258a250.714 250.714 0 0 1-72.088 19.772c25.929-15.527 45.777-40.155 55.184-69.411-24.322 14.379-51.169 24.82-79.775 30.48-22.907-24.437-55.49-39.658-91.63-39.658-69.334 0-125.551 56.217-125.551 125.513 0 9.828 1.109 19.427 3.251 28.606-104.326-5.24-196.835-55.223-258.75-131.174-10.823 18.51-16.98 40.078-16.98 63.101 0 43.559 22.181 81.993 55.835 104.479a125.556 125.556 0 0 1-56.867-15.756v1.568c0 60.806 43.291 111.554 100.693 123.104-10.517 2.83-21.607 4.398-33.08 4.398-8.107 0-15.947-.803-23.634-2.333 15.985 49.907 62.336 86.199 117.253 87.194-42.947 33.654-97.099 53.655-155.916 53.655-10.134 0-20.116-.612-29.944-1.721 55.567 35.681 121.536 56.485 192.438 56.485 230.948 0 357.188-191.291 357.188-357.188l-.421-16.253c24.666-17.593 46.005-39.697 62.794-64.861z" fill="#010002"/></svg>
    
    </a>
    
    
    <a href="http://jorgelbg.github.io/index.xml" class="symbol rss">
        <svg height="28" version="1" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 559 559"><path d="M53 0a497 497 0 0 1 358 148 508 508 0 0 1 148 358c0 15-5 27-15 38a51 51 0 0 1-38 15c-15 0-27-5-38-15a51 51 0 0 1-15-38 390 390 0 0 0-117-282A400 400 0 0 0 53 106 52 52 0 0 1 0 53c0-14 5-27 16-37C26 5 39 0 53 0zm0 201c42 0 82 8 119 25s69 37 96 65a312 312 0 0 1 90 215c0 15-5 27-16 38a51 51 0 0 1-37 15c-15 0-27-5-38-15a51 51 0 0 1-15-38 192 192 0 0 0-59-140 201 201 0 0 0-140-58c-14 0-27-5-37-16-11-10-16-23-16-37s5-28 16-38c10-10 23-16 37-16zm98 280a73 73 0 0 1-45 69c-10 4-19 6-30 6a73 73 0 0 1-68-46 74 74 0 0 1 39-98 74 74 0 0 1 104 69z" fill="#010002"/></svg>
    </a>
    
</div>

    
    <p class="small">
    
        ¬© Copyright 2019 Jorge Luis Betancourt
    
    </p>
</footer>

    </section>
    

<script src="http://jorgelbg.github.io/js/highlight.js"></script>
<script>hljs.initHighlightingOnLoad();</script>




<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
	(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
	m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
	ga('create', 'UA-115201846-1', 'auto');
	
	ga('send', 'pageview');
}
</script>


</body>
</html>
